{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxqsa4rtJz1r6dFbwm9Fb3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9xt-vjhjmM5V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "train_data = datasets.MNIST(root='/mnist_data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='/mnist_data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=20, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=20, shuffle=False)"
      ],
      "metadata": {
        "id": "BYV7chdKwRiJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
        "    self.fc1 = nn.Linear(5*5*16, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = f.relu(self.conv1(X))\n",
        "    X = f.max_pool2d(X, 2, 2)\n",
        "    X = f.relu(self.conv2(X))\n",
        "    X = f.max_pool2d(X, 2, 2)\n",
        "\n",
        "    X = X.view(-1, 16*5*5)\n",
        "    X = f.relu(self.fc1(X))\n",
        "    X = f.relu(self.fc2(X))\n",
        "    X = self.fc3(X)\n",
        "\n",
        "    return f.log_softmax(X, dim=1)"
      ],
      "metadata": {
        "id": "uIJpQbDa1DuP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(30)\n",
        "model = ConvNetwork()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "\n",
        "epochs = 3\n",
        "losses = []\n",
        "accuracy = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  correct = 0\n",
        "  size = 0\n",
        "  for b, (X_train, y_train) in enumerate(train_loader):\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    predicted = torch.max(y_pred.data, 1)[1]\n",
        "\n",
        "    #amount of correct predictions in current batch\n",
        "    batch_corr = (predicted == y_train).sum()\n",
        "    correct += batch_corr\n",
        "    size += int(y_train.size()[0])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if b%800 == 0:\n",
        "      print(f'Epoch {epoch}, batch number {b} loss {loss}')\n",
        "\n",
        "  losses.append(loss)\n",
        "  accuracy.append(correct/size)\n",
        "\n",
        "print(f'losses: {losses}')\n",
        "print(f'acc: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqXZ54fI2dnO",
        "outputId": "a9f53a46-79b8-4484-ca73-8a60c566018b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, batch number 0 loss 2.303067445755005\n",
            "Epoch 0, batch number 800 loss 0.15863728523254395\n",
            "Epoch 0, batch number 1600 loss 0.10212469846010208\n",
            "Epoch 0, batch number 2400 loss 0.1581864207983017\n",
            "Epoch 0, batch number 3200 loss 0.015582998283207417\n",
            "Epoch 0, batch number 4000 loss 0.013652809895575047\n",
            "Epoch 0, batch number 4800 loss 0.046348389238119125\n",
            "Epoch 0, batch number 5600 loss 0.14677436649799347\n",
            "Epoch 0, batch number 6400 loss 0.22526387870311737\n",
            "Epoch 0, batch number 7200 loss 0.013300127349793911\n",
            "Epoch 0, batch number 8000 loss 0.018726753070950508\n",
            "Epoch 1, batch number 0 loss 0.031052665784955025\n",
            "Epoch 1, batch number 800 loss 0.033464618027210236\n",
            "Epoch 1, batch number 1600 loss 0.009655318222939968\n",
            "Epoch 1, batch number 2400 loss 0.043690502643585205\n",
            "Epoch 1, batch number 3200 loss 0.0014886591816321015\n",
            "Epoch 1, batch number 4000 loss 0.14464183151721954\n",
            "Epoch 1, batch number 4800 loss 0.020114904269576073\n",
            "Epoch 1, batch number 5600 loss 0.001312742941081524\n",
            "Epoch 1, batch number 6400 loss 0.0025889254175126553\n",
            "Epoch 1, batch number 7200 loss 0.0024443597067147493\n",
            "Epoch 1, batch number 8000 loss 0.006186657585203648\n",
            "Epoch 2, batch number 0 loss 0.07012049108743668\n",
            "Epoch 2, batch number 800 loss 0.002498256042599678\n",
            "Epoch 2, batch number 1600 loss 0.0002471875923220068\n",
            "Epoch 2, batch number 2400 loss 0.17555639147758484\n",
            "Epoch 2, batch number 3200 loss 0.00642826734110713\n",
            "Epoch 2, batch number 4000 loss 0.0814257487654686\n",
            "Epoch 2, batch number 4800 loss 0.0370975062251091\n",
            "Epoch 2, batch number 5600 loss 0.0021489348728209734\n",
            "Epoch 2, batch number 6400 loss 0.01726810447871685\n",
            "Epoch 2, batch number 7200 loss 0.0037275024224072695\n",
            "Epoch 2, batch number 8000 loss 0.0008171848021447659\n",
            "losses: [tensor(0.0009, grad_fn=<NllLossBackward0>), tensor(0.0052, grad_fn=<NllLossBackward0>), tensor(0.0003, grad_fn=<NllLossBackward0>)]\n",
            "acc: [tensor(0.9163), tensor(0.9712), tensor(0.9801)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  size = 0\n",
        "  for b, (X_test, y_test) in enumerate(test_loader):\n",
        "    y_pred = model(X_test)\n",
        "    predicted = torch.max(y_pred.data, 1)[1]\n",
        "    batch_corr = (predicted == y_test).sum()\n",
        "    correct += batch_corr\n",
        "    size += int(y_test.size()[0]) #batch size\n",
        "\n",
        "accuracy = correct/size\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_MI1_IzI0z0",
        "outputId": "2ec8292c-b37d-413b-ec57-a1c7a1e9bf9f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9857)\n"
          ]
        }
      ]
    }
  ]
}